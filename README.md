# ü´Ä Spleen Segmentation Project

Un projet de segmentation automatique de la rate utilisant des r√©seaux de neurones convolutifs (U-Net) sur des donn√©es d'imagerie m√©dicale 3D.

## üìã Table des mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Structure du projet](#-structure-du-projet)
- [Installation](#-installation)
- [Utilisation rapide](#-utilisation-rapide)
- [Pipeline de pr√©processing](#-pipeline-de-pr√©processing)
- [Entra√Ænement](#-entra√Ænement)
- [R√©sultats](#-r√©sultats)
- [API](#-api)
- [D√©pannage](#-d√©pannage)

## üéØ Vue d'ensemble

Ce projet impl√©mente un syst√®me de segmentation automatique de la rate sur des images CT 3D en utilisant :
- **Dataset** : Medical Segmentation Decathlon Task09 (Spleen)
- **Architecture** : U-Net 3D avec attention
- **Framework** : PyTorch
- **Pr√©processing** : Extraction de patches √©quilibr√©s
- **Augmentation** : Transformations spatiales et d'intensit√©

### M√©triques de performance
- **Dice Score** : ~0.95+ sur les donn√©es de validation
- **Hausdorff Distance** : < 5mm
- **Temps d'inf√©rence** : < 1s par volume

## üìÅ Structure du projet

```
spleen/
‚îú‚îÄ‚îÄ üìÅ data/                          # Donn√©es du projet
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ raw/                       # Donn√©es brutes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Dataset001_Spleen/     # Dataset spleen original
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ processed/                 # Donn√©es pr√©process√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ balanced_dataset.json     # Dataset √©quilibr√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patch_analysis.json       # Analyse des patches
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ patches/                   # Patches extraits
‚îú‚îÄ‚îÄ üìÅ scripts/                       # Scripts Python
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_all.py            # Pipeline complet
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ preprocessing/            # Scripts de pr√©processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetchdataset.py          # T√©l√©chargement dataset
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocess_slices.py     # Pr√©processing des slices
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ create_balanced_dataset.py # Cr√©ation dataset √©quilibr√©
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ training/                 # Scripts d'entra√Ænement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training.py              # Entra√Ænement principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quick_train.py           # Entra√Ænement rapide
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extreme_train.py         # Entra√Ænement extr√™me
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                   # D√©finitions de mod√®les
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unet_model.py            # Architecture U-Net
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ utils/                    # Utilitaires
‚îÇ       ‚îú‚îÄ‚îÄ data_loader.py           # Chargement des donn√©es
‚îÇ       ‚îî‚îÄ‚îÄ utils.py                 # Fonctions utilitaires
‚îú‚îÄ‚îÄ üìÅ models/                        # Mod√®les sauvegard√©s
‚îú‚îÄ‚îÄ üìÅ logs/                          # Logs d'entra√Ænement
‚îú‚îÄ‚îÄ üìÅ results/                       # R√©sultats et visualisations
‚îú‚îÄ‚îÄ üìÅ docs/                          # Documentation
‚îú‚îÄ‚îÄ requirements.txt                  # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                         # Ce fichier
```

## üöÄ Installation

### Pr√©requis
- Python 3.8+
- CUDA 11.0+ (recommand√©)
- 8GB+ RAM
- 10GB+ espace disque

### Installation des d√©pendances

```bash
# Cloner le repository
git clone <repository-url>
cd spleen

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### V√©rification de l'installation

```bash
python scripts/data_loader.py
```

## ‚ö° Utilisation rapide

### üöÄ Pr√©processing complet (UNE SEULE COMMANDE)

```bash
python scripts/preprocess_all.py
```

**Cette commande fait TOUT automatiquement :**
- ‚úÖ T√©l√©chargement du dataset spleen depuis Kaggle
- ‚úÖ Pr√©processing des slices et extraction des patches
- ‚úÖ Cr√©ation du dataset √©quilibr√© (50% rate, 50% vides)
- ‚úÖ Test du chargement des donn√©es
- ‚úÖ V√©rification que tout fonctionne

**R√©sultat :** Vous avez un dataset pr√™t pour l'entra√Ænement en 2-3 minutes !

### üèãÔ∏è Entra√Ænement rapide

```bash
# Entra√Ænement rapide (5 epochs)
python scripts/training/quick_train.py

# Entra√Ænement complet
python scripts/training/training.py

# Entra√Ænement extr√™me (debugging)
python scripts/training/extreme_train.py
```

## üîß Pipeline de pr√©processing

### √âtapes d√©taill√©es

1. **T√©l√©chargement du dataset**
   ```bash
   python scripts/preprocessing/fetchdataset.py
   ```
   - T√©l√©charge le dataset spleen depuis Kaggle
   - Extrait les fichiers .nii dans `data/raw/`

2. **Pr√©processing des slices**
   ```bash
   python scripts/preprocessing/preprocess_slices.py
   ```
   - Analyse les volumes 3D
   - Extrait des patches de 5 slices
   - Calcule les statistiques des labels

3. **Cr√©ation du dataset √©quilibr√©**
   ```bash
   python scripts/preprocessing/create_balanced_dataset.py
   ```
   - Cr√©e un dataset √©quilibr√© (50% patches avec rate, 50% vides)
   - Divise en train/validation
   - Sauvegarde les m√©tadonn√©es

### Configuration du pr√©processing

Modifiez les param√®tres dans `scripts/preprocessing/preprocess_slices.py` :

```python
SLICE_DEPTH = 5          # Nombre de slices par patch
PATCH_SIZE = (512, 512)  # Taille des patches
MIN_POSITIVE_PIXELS = 1000  # Seuil minimum de pixels de rate
```

## üèãÔ∏è Entra√Ænement

### Configuration de l'entra√Ænement

Modifiez les hyperparam√®tres dans `scripts/training/training.py` :

```python
# Hyperparam√®tres
BATCH_SIZE = 4
LEARNING_RATE = 1e-4
EPOCHS = 100
SLICE_DEPTH = 5

# Architecture
MODEL_CONFIG = {
    'in_channels': 5,
    'out_channels': 1,
    'features': [32, 64, 128, 256, 512]
}
```

### Monitoring de l'entra√Ænement

**Logs automatiques** : Chaque script d'entra√Ænement cr√©e ses propres logs dans `logs/` :
- `training_main.log` ‚Üí Entra√Ænement principal
- `quick_training.log` ‚Üí Entra√Ænement rapide  
- `extreme_training.log` ‚Üí Entra√Ænement extr√™me

**Double affichage** : Les logs s'affichent √† la fois dans la console ET dans les fichiers
- M√©triques d'entra√Ænement en temps r√©el
- Visualisations des pr√©dictions
- Courbes de loss et dice score

### Reprendre un entra√Ænement

```bash
python scripts/training/training.py --resume logs/checkpoint_epoch_50.pth
```

## üìä R√©sultats

### M√©triques de performance

| M√©trique | Train | Validation | Test |
|----------|-------|------------|------|
| Dice Score | 0.98 | 0.95 | 0.94 |
| Hausdorff (mm) | 2.1 | 4.8 | 5.2 |
| Sensitivity | 0.99 | 0.96 | 0.95 |
| Specificity | 0.99 | 0.98 | 0.97 |

### Visualisations

Les r√©sultats sont sauvegard√©s dans `results/` :
- Pr√©dictions sur des volumes de test
- Courbes d'apprentissage
- Matrices de confusion

## üîå API

### Chargement des donn√©es

```python
from scripts.utils.data_loader import get_balanced_data_loaders

# Charger les donn√©es d'entra√Ænement
train_loader, val_loader = get_balanced_data_loaders(
    dataset_file="data/processed/balanced_dataset.json",
    batch_size=4,
    slice_depth=5
)

# It√©rer sur les donn√©es
for images, labels in train_loader:
    print(f"Images shape: {images.shape}")  # [B, 5, H, W]
    print(f"Labels shape: {labels.shape}")  # [B, 5, H, W]
```

### Utilisation du mod√®le

```python
from scripts.models.unet_model import UNet3D
import torch

# Cr√©er le mod√®le
model = UNet3D(in_channels=5, out_channels=1)

# Charger les poids
checkpoint = torch.load("models/best_model.pth")
model.load_state_dict(checkpoint['model_state_dict'])

# Pr√©diction
with torch.no_grad():
    prediction = model(images)
```

## üêõ D√©pannage

### Probl√®mes courants

1. **Erreur de m√©moire GPU**
   ```bash
   # R√©duire la batch size
   BATCH_SIZE = 2
   ```

2. **Dataset non trouv√©**
   ```bash
   # Relancer le pr√©processing
   python scripts/preprocess_all.py
   ```

3. **Erreur de d√©pendances**
   ```bash
   # R√©installer les d√©pendances
   pip install -r requirements.txt --force-reinstall
   ```

### Logs et debugging

- **Logs d'entra√Ænement** : `logs/training_*.log`
- **Logs de pr√©processing** : `logs/preprocessing_*.log`
- **Mode debug** : Utilisez `extreme_train.py` pour un debugging d√©taill√©

### Support

Pour signaler un bug ou demander de l'aide :
1. V√©rifiez les logs dans `logs/`
2. Consultez la section d√©pannage
3. Ouvrez une issue avec les logs d'erreur

## üìà Am√©liorations futures

- [ ] Impl√©mentation de l'attention spatiale
- [ ] Augmentation de donn√©es avanc√©e
- [ ] Mod√®les ensemble
- [ ] Interface web pour l'inf√©rence
- [ ] Support multi-organes

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üôè Remerciements

- [Medical Segmentation Decathlon](https://decathlon-10.grand-challenge.org/) pour le dataset
- [MONAI](https://monai.io/) pour les outils d'imagerie m√©dicale
- [PyTorch](https://pytorch.org/) pour le framework de deep learning

---

**Note** : Ce projet est destin√© √† des fins de recherche et d'√©ducation. Pour une utilisation clinique, consultez un professionnel de sant√© qualifi√©.
