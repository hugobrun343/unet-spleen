# Spleen Segmentation - 2D U-Net avec contexte 3D

Segmentation automatique de la rate avec U-Net 2D (5 slices de contexte) sur des images CT mÃ©dicales.

## ğŸš€ Quick Start

### 1. PrÃ©processing
```bash
# Preprocessing complet (tÃ©lÃ©charge, analyse, crÃ©e les 2 datasets)
python scripts/preprocessing/preprocess_all.py
```

### 2. EntraÃ®nement

**Dataset SPLIT (labeled rÃ©partis partout) :**
```bash
python scripts/training/train_split.py --epochs 100
```

**Dataset STACK (labeled + adjacents pour post-processing) :**
```bash
python scripts/training/train_stack.py --epochs 100
```

**ParamÃ¨tres train_split.py (PATCHES) :**
```bash
--epochs 100          # Nombre d'epochs (dÃ©faut: 100)
--batch_size 1        # Taille du batch (dÃ©faut: 1)
--lr 0.001            # Learning rate (dÃ©faut: 1e-3)
--num_workers 1       # Workers pour le data loader (dÃ©faut: 1)
--train_patches 400   # Nombre de patches train (dÃ©faut: None = tous)
--val_patches 100     # Nombre de patches val (dÃ©faut: None = tous)
```

**ParamÃ¨tres train_stack.py (VOLUMES) :**
```bash
--epochs 100          # Nombre d'epochs (dÃ©faut: 100)
--batch_size 1        # Taille du batch (dÃ©faut: 1)
--lr 0.001            # Learning rate (dÃ©faut: 1e-3)
--num_workers 1       # Workers pour le data loader (dÃ©faut: 1)
--train_volumes 20    # Nombre de volumes train (dÃ©faut: None = tous)
--val_volumes 5       # Nombre de volumes val (dÃ©faut: None = tous)
```

**Exemples d'utilisation :**
```bash
# SPLIT: Quick test avec 400 train patches + 100 val patches (50/50 labeled/unlabeled auto)
python scripts/training/train_split.py --epochs 50 --train_patches 400 --val_patches 100

# STACK: Train sur 20 volumes (tous leurs patches) + 5 volumes val
python scripts/training/train_stack.py --epochs 100 --train_volumes 20 --val_volumes 5

# Full training avec tous les volumes (pour post-processing optimal)
python scripts/training/train_stack.py --epochs 200

# Training avec batch size plus grand (si GPU le permet)
python scripts/training/train_split.py --epochs 100 --batch_size 4
```

### 3. Ã‰valuation avec post-processing
```bash
# Ã‰valuer avec connected components (vire les faux positifs)
python scripts/postprocessing/evaluate_volume.py \
    --checkpoint checkpoints/stack/best_model.pth \
    --num_volumes 5
```

**ParamÃ¨tres Ã©valuation :**
```bash
--checkpoint PATH     # Chemin vers le checkpoint (.pth) (requis)
--num_volumes 5       # Nombre de volumes Ã  Ã©valuer (dÃ©faut: 5)
```

### 4. Analyse des logs
```bash
# GÃ©nÃ©rer rÃ©sumÃ© + graphiques depuis un log
python scripts/utils/analyze_logs.py logs/train_split.log
```

GÃ©nÃ¨re automatiquement :
- `train_split_summary.txt` - RÃ©sumÃ© texte dÃ©taillÃ©
- `train_split_loss.png` - Graphique Loss
- `train_split_dice.png` - Graphique Dice Score
- `train_split_iou.png` - Graphique IoU
- `train_split_lr.png` - Graphique Learning Rate

## ğŸ“Š Datasets

**2 datasets disponibles :**

1. **`dataset_split.json`** (distributed)
   - TOUS les patches labeled (1207)
   - MÃªme quantitÃ© d'unlabeled (933) rÃ©partis uniformÃ©ment
   - Unlabeled Ã©vitent les bordures (10%)
   - ~28000 lignes

2. **`dataset_stack.json`** (adjacent for post-processing)
   - TOUS les patches labeled (1207)
   - Unlabeled AUTOUR des labeled (470) dans un rayon de Â±5 slices
   - OptimisÃ© pour reconstruction 3D et post-processing
   - ~21000 lignes

## ğŸ“ Structure

```
spleen/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Dataset original
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ patch_analysis.json     # Analyse des patches
â”‚       â”œâ”€â”€ dataset_split.json      # Dataset distributed
â”‚       â””â”€â”€ dataset_stack.json      # Dataset adjacent
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ preprocess_all.py       # Pipeline complet
â”‚   â”‚   â”œâ”€â”€ fetchdataset.py
â”‚   â”‚   â”œâ”€â”€ preprocess_slices.py
â”‚   â”‚   â”œâ”€â”€ create_split_dataset.py
â”‚   â”‚   â””â”€â”€ create_stack_dataset.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_split.py          # Train sur split
â”‚   â”‚   â””â”€â”€ train_stack.py          # Train sur stack
â”‚   â”œâ”€â”€ postprocessing/
â”‚   â”‚   â”œâ”€â”€ evaluate_volume.py      # Ã‰valuation 3D
â”‚   â”‚   â””â”€â”€ utils.py                # Connected components 3D
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ unet_model.py           # U-Net 2D
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ utils.py
â”‚       â””â”€â”€ analyze_logs.py         # Analyse des logs
â”œâ”€â”€ logs/                           # Logs d'entraÃ®nement
â”‚   â”œâ”€â”€ train_split.log
â”‚   â””â”€â”€ train_stack.log
â”œâ”€â”€ checkpoints/                    # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ split/
â”‚   â”‚   â”œâ”€â”€ checkpoint_epoch_X.pth
â”‚   â”‚   â””â”€â”€ best_model.pth
â”‚   â””â”€â”€ stack/
â”‚       â”œâ”€â”€ checkpoint_epoch_X.pth
â”‚       â””â”€â”€ best_model.pth
â””â”€â”€ results/                        # RÃ©sultats d'Ã©valuation
```

## ğŸ§  Architecture

- **ModÃ¨le** : U-Net 2D avec 5 slices de contexte (5 channels d'entrÃ©e)
- **Input** : 5 slices consÃ©cutives de 512x512 pixels
- **Output** : 1 slice de segmentation 512x512 pixels
- **Framework** : PyTorch
- **Loss** : BCEWithLogitsLoss
- **Optimizer** : Adam avec ReduceLROnPlateau

## ğŸ§¹ Post-processing

Le post-processing 3D avec **connected components** amÃ©liore les rÃ©sultats :
- Reconstruction du volume 3D depuis les prÃ©dictions 2D
- DÃ©tection des composantes connexes
- Conservation uniquement du plus gros blob (la rate)
- Suppression des faux positifs

**Pourquoi dataset_stack ?** Les unlabeled adjacents aux labeled permettent une meilleure reconstruction du volume complet.

## ğŸ”§ Configuration

**Dataset :**
- Source : Medical Segmentation Decathlon Task09 (Spleen)
- 41 volumes d'entraÃ®nement
- 20 volumes de test
- RÃ©solution : 512x512 pixels
- Slice depth : 5

**Checkpoints :**
- Sauvegarde du dernier checkpoint Ã  chaque epoch
- Sauvegarde du meilleur modÃ¨le (Val Dice) dans `best_model.pth`

**Logs :**
- Console + fichier log
- MÃ©triques : Loss, Dice, IoU
- Learning rate Ã  chaque epoch

**Analyse des logs :**
```bash
# GÃ©nÃ©rer graphiques et rÃ©sumÃ© depuis un log
python scripts/utils/analyze_logs.py logs/train_split.log
```

## ğŸ’¡ ProblÃ¨mes courants

**CUDA out of memory :**
```bash
# Tuer les processus
pkill -f python

# RÃ©duire le batch size
python scripts/training/train_split.py --batch_size 1
```

**Dataset manquant :**
```bash
python scripts/preprocess_all.py
```

## ğŸ“ˆ RÃ©sultats attendus

- **Dice Score** : ~0.60-0.70 (patch-based)
- **AmÃ©lioration post-processing** : +5-10% Dice
- **Temps d'entraÃ®nement** : ~2-5h pour 100 epochs (selon GPU)

## ğŸ¯ Workflow recommandÃ©

### Quick Start (test rapide)
```bash
# 1. Preprocessing complet
python scripts/preprocessing/preprocess_all.py

# 2. Quick training (500 patches, 50 epochs)
python scripts/training/train_stack.py --epochs 50 --max_patches 500

# 3. Analyser les rÃ©sultats
python scripts/utils/analyze_logs.py logs/train_stack.log

# 4. Ã‰valuer avec post-processing
python scripts/postprocessing/evaluate_volume.py \
    --checkpoint checkpoints/stack/best_model.pth \
    --num_volumes 3
```

### Full Training (production)
```bash
# 1. Train sur tous les patches
python scripts/training/train_stack.py --epochs 200

# 2. Ã‰valuer sur plus de volumes
python scripts/postprocessing/evaluate_volume.py \
    --checkpoint checkpoints/stack/best_model.pth \
    --num_volumes 10

# 3. Analyser
python scripts/utils/analyze_logs.py logs/train_stack.log
```
